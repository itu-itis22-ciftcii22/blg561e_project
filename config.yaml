# Configuration for Token Malice Prediction - Ablation Study

# Base configuration (shared across all runs)
base:
  data:
    data_dir: "data/bq_data_100plus"
    num_snapshots: 6
    cache_path: "data/graph_cache.pt"
  
  training:
    test_ratio: 0.2
    val_ratio: 0.1
    batch_size: 16
    learning_rate: 0.01
    weight_decay: 0.01
    num_epochs: 1
    gradient_clip: 1.0
  
  output_dir: "./outputs"
  seed: 42
  device: "cuda"

# Experiment runs (each overrides model config from base)
runs:
  # Hidden dimension ablation
  - name: "hidden_32"
    model:
      hidden_dim: 32
      num_heads: 2
      dropout: 0.2
      pooling: "concat"

  - name: "hidden_64"
    model:
      hidden_dim: 64
      num_heads: 2
      dropout: 0.2
      pooling: "concat"

  - name: "hidden_128"
    model:
      hidden_dim: 128
      num_heads: 2
      dropout: 0.2
      pooling: "concat"
